{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust-NTF Applied to Missing Data\n",
    "\n",
    "Here, we generate a synthetic low-rank 3-dimensional tensor from known signals. Some of the data is removed (set to NaN) mirroring hyperspectral autofluorescence image cubes. The data is processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torch.nn.functional import normalize\n",
    "from scipy import signal\n",
    "from scipy.stats import gamma\n",
    "from tensorly.kruskal_tensor import kruskal_to_tensor\n",
    "from tensorly.decomposition.candecomp_parafac import non_negative_parafac\n",
    "from tensorly.tenalg.outer_product import outer\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from robust_ntf.robust_ntf import RntfConfig, RobustNTF, RntfStats\n",
    "\n",
    "# Use the GPU at fp64 by default:\n",
    "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "# Make TensorLy use PyTorch:\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "# Set RNG seeds:\n",
    "torch.manual_seed(33)\n",
    "np.random.seed(33)\n",
    "\n",
    "# Set an epsilon to protect against zeros:\n",
    "eps = 1e-6"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate synthetic tensor\n",
    "\n",
    "### Generate ground truth factors:\n",
    "\n",
    "Over here, we generate ground truth factor matrices to generate a rank-3 synthetic tensor with. They include,\n",
    "\n",
    "* A Gaussian modulated sinusoid and take its real and imaginary parts, and its envelope to be the ground truth factors.\n",
    "* Three different chirp signals.\n",
    "* Three different Gamma PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "## Mode-1 generation ##\n",
    "#######################\n",
    "\n",
    "# Sample 50 points:\n",
    "mode1_support = np.linspace(-1, 1, 2*25, endpoint=False)\n",
    "\n",
    "# Generate signal and plot:\n",
    "x1, x2, x3 = signal.gausspulse(mode1_support, fc=3,\n",
    "                               retquad=True, retenv=True)\n",
    "x1 = 2 * np.abs(x1)\n",
    "x2 = 2 * np.abs(x2)\n",
    "x3 = 2 * np.abs(x3)\n",
    "\n",
    "#######################\n",
    "## Mode-2 generation ##\n",
    "#######################\n",
    "\n",
    "mode2_support = np.linspace(-1, 1, 96, endpoint=False)\n",
    "y1 = signal.chirp(mode2_support, f0=4, t1=-0.5, f1=4)\n",
    "y2 = signal.chirp(mode2_support, f0=2, t1=0.5, f1=3)\n",
    "y3 = signal.chirp(mode2_support, f0=1, t1=0.1, f1=2)\n",
    "\n",
    "y1 = y1 - y1.min()\n",
    "y2 = y2 - y2.min()\n",
    "y3 = y3 - y3.min()\n",
    "\n",
    "#######################\n",
    "## Mode-3 generation ##\n",
    "#######################\n",
    "\n",
    "mode3_support = np.linspace(0, 10, 20)\n",
    "\n",
    "z1 = gamma(7).pdf(mode3_support)\n",
    "z2 = gamma(2).pdf(mode3_support)\n",
    "z3 = gamma(4).pdf(mode3_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ground truth factors:"
   ]
  },
  {
   "source": [
    "# Set up figure size:\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "# Plot factors:\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(mode1_support, x1,\n",
    "         mode1_support, x2,\n",
    "         mode1_support, x3)\n",
    "plt.gca().set_title('Mode-1 factors')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(mode2_support, y1,\n",
    "         mode2_support, y2,\n",
    "         mode2_support, y3)\n",
    "plt.gca().set_title('Mode-2 factors')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(mode3_support, z1,\n",
    "         mode3_support, z2,\n",
    "         mode3_support, z3)\n",
    "plt.gca().set_title('Mode-3 factors')"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast factors to PyTorch and/or make positive:"
   ]
  },
  {
   "source": [
    "# Mode-1:\n",
    "X = np.array([x1, x2, x3])\n",
    "X = torch.from_numpy(X).cuda() + eps\n",
    "\n",
    "# Mode-2:\n",
    "Y = np.array([y1, y2, y3])\n",
    "Y = torch.from_numpy(Y).cuda() + eps\n",
    "\n",
    "# Mode-3:\n",
    "Z = np.array([z1, z2, z3])\n",
    "Z = torch.from_numpy(Z).cuda() + eps"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct ground truth tensor to factorize:"
   ]
  },
  {
   "source": [
    "# Construct Kruskal tensor in TensorLy format:\n",
    "ktens = (None, [X.t(), Y.t(), Z.t()])\n",
    "\n",
    "# Construct dense tensor:\n",
    "data = kruskal_to_tensor(ktens)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[-1]):\n",
    "    data[-int(1.5*i)-1:, :, i+1:] = np.nan\n",
    "np.isnan(data.cpu().numpy()).sum() / data.cpu().numpy().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some slices of the tensor in false color:"
   ]
  },
  {
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "# XY\n",
    "plt.subplot(2,2,1)\n",
    "XY = data[:, :, 0:3].data.cpu().numpy()\n",
    "XY = XY / np.nanmax(XY)\n",
    "plt.imshow(XY)\n",
    "\n",
    "# XZ\n",
    "plt.subplot(2,2,2)\n",
    "XZ = data[:, 0:3, :].data.cpu().numpy()\n",
    "XZ = XZ.transpose([0, 2, 1])\n",
    "XZ = XZ / np.nanmax(XZ)\n",
    "plt.imshow(XZ)\n",
    "\n",
    "# ZY\n",
    "plt.subplot(2,2,3)\n",
    "ZY = data[0:3, :, :].data.cpu().numpy()\n",
    "ZY = ZY.transpose([2, 1, 0])\n",
    "ZY = ZY / np.nanmax(ZY)\n",
    "plt.imshow(ZY)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {
    "tags": []
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Compare methods\n",
    "\n",
    "Run the cells below with error tolerance 1e-2 and then 1e-3 and compare."
   ]
  },
  {
   "source": [
    "ERROR_TOLERANCE = 1e-2\n",
    "\n",
    "cfg = RntfConfig(3, 2, 0.1, ERROR_TOLERANCE, max_iter=200000, print_every=100, save_every=100, save_folder=\"./out\")\n",
    "rntf = RobustNTF(cfg)\n",
    "rntf.run(data)\n",
    "rntf_01_factors = rntf.matrices\n",
    "rntf_01_outlier = rntf.outlier\n",
    "vals = rntf.stats"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {
    "tags": []
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize objective, error, and reconstruction accuracy statistics. At 1e-3 local minima should be visible that dip below 1e-2, which would cause early stopping at 1e-2. The regularization term also drops sharply at one point, a possible indicator of convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,15))\n",
    "\n",
    "inds = list(range(len(vals[\"error\"])))\n",
    "x_end = np.log10(inds[-1]) - 0.02\n",
    "\n",
    "plt.subplot(4,1,1)\n",
    "obj = vals[RntfStats.OBJ].to_numpy()\n",
    "plt.plot(np.log10(inds[0:]), np.log10(obj[0:]))\n",
    "plt.annotate(\"Objective\", xy=(x_end, np.log10(obj[-1])+0.1), horizontalalignment=\"right\")\n",
    "fit = vals[RntfStats.FIT].to_numpy()\n",
    "plt.plot(np.log10(inds[0:]), np.log10(fit[0:]), linestyle=\"dashed\", color=\"gray\")\n",
    "plt.annotate(\"Fitness (Beta Divergence)\", xy=(x_end, np.log10(fit[-1])+0.1), horizontalalignment=\"right\")\n",
    "reg = vals[RntfStats.REG].to_numpy()\n",
    "plt.plot(np.log10(inds[0:]), np.log10(reg[0:]), linestyle=\":\", color=\"gray\")\n",
    "plt.annotate(\"Regularization Term ($L_{2,1}$ Norm)\", xy=(x_end, np.log10(reg[-1])-0.08), horizontalalignment=\"right\", verticalalignment=\"top\")\n",
    "plt.title(\"Objective Function\")\n",
    "\n",
    "plt.subplot(4,1,2)\n",
    "err = vals[RntfStats.ERR].to_numpy()\n",
    "plt.plot(np.log10(inds[0:]), np.log10(err[0:]))\n",
    "plt.title(\"Relative Change in Objective Function (Error)\")\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "L2_acc = vals[RntfStats.L2_ACC].to_numpy()\n",
    "plt.plot(np.log10(inds[0:]), np.log10(L2_acc[0:]))\n",
    "plt.title(\"Accuracy ($L_{2}$ Norm)\")\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "Linf_acc = vals[RntfStats.LINF_ACC].to_numpy()\n",
    "plt.plot(np.log10(inds[0:]), np.log10(Linf_acc[0:]))\n",
    "plt.title(\"Accuracy ($L_{inf}$ Norm)\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some factors:\n",
    "Here, mode-3 factors for NTF and rNTF are plotted. At 1e-2 they are noisy. At 1e-3 they are very close to the input mode-3 factors."
   ]
  },
  {
   "source": [
    "# Set up figure size:\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(normalize(rntf_01_factors[2], dim=0).data.cpu().numpy())\n",
    "plt.gca().set_title('robust-NTF Mode-3 results')"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize reconstructions: Data vs rNTF\n",
    "\n",
    "At 1e-2 the reconstruction is nothing like the original dataset. At 1e-3 they are almost exactly identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct rNTF factors:\n",
    "rntf_recon = torch.zeros(50,96,20)\n",
    "\n",
    "for i in range(3):\n",
    "    rntf_recon = rntf_recon + outer([rntf_01_factors[0][:,i],\n",
    "                                     rntf_01_factors[1][:,i],\n",
    "                                     rntf_01_factors[2][:,i]])\n",
    "\n",
    "## Plot results:\n",
    "# Set up figure size:\n",
    "fig = plt.figure(figsize=(10, 15))\n",
    "\n",
    "# Plot original data:\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(data[:, 0, :].data.cpu().numpy())\n",
    "plt.gca().set_title('Original data slices')\n",
    "# Plot rNTF reconstruction:\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(rntf_recon[:, 0, :].data.cpu().numpy())\n",
    "plt.gca().set_title('Robust-NTF reconstruction slices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize outliers\n",
    "\n",
    "The percentage value is the maximum value of the outliers divided by the maximum value of the original data. This is a measure of the severity of the outliers. Since there is no noise in the original data, we expect a near-perfect reconstruction, and the maximum outlier value to be very small.\n",
    "\n",
    "At 1e-2 the outliers are noisy, and contain considerable information that belongs in the reconstruction, reflected in the large percentage. At 1e-3 almost no information is in the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Plot results:\n",
    "# Set up figure size:\n",
    "fig = plt.figure(figsize=(10, 15))\n",
    "\n",
    "# Plot original data:\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(data[:, 0, :].data.cpu().numpy())\n",
    "plt.gca().set_title('Original data slices')\n",
    "\n",
    "# Plot rNTF reconstruction:\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(rntf_01_outlier[25, :, :].data.cpu().numpy())\n",
    "plt.gca().set_title('Robust-NTF outlier slices')\n",
    "\n",
    "out = np.nanmax(rntf_01_outlier[:, :, :].cpu().numpy()) / np.nanmax(data[:, :, :].cpu().numpy())\n",
    "print(\"Outlier max / data max: {:.1%}\".format(out.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}